{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPlKtzU1imXU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn # contains nn framework\n",
        "\n",
        "from torch.utils.data import DataLoader # Split data into batches\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets # import fashionMNIST data for use\n",
        "from torchvision import transforms # to manipulate data for use in model\n",
        "from torchvision.transforms import ToTensor # to have data in tensor format\n",
        "\n",
        "import matplotlib.pyplot as plt # Plot data\n",
        "\n",
        "import requests # to save and load model to designated path\n",
        "from pathlib import Path\n",
        "\n",
        "from timeit import default_timer as timer # To time training and evaluation of model\n",
        "\n",
        "from tqdm.auto import tqdm # progress bar\n",
        "\n",
        "import random\n",
        "\n",
        "try:\n",
        "  import torchmetrics, mlxtend\n",
        "  assert int(mlxtend.__version__.split(\".\")[1] >= 19, \"mlxtend version should be 0.19.0 or higher\")\n",
        "except:\n",
        "  !pip install -q torchmetrics -U mlxtend\n",
        "  import torchmetrics, mlxtend\n",
        "  print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "\n",
        "from torchmetrics import ConfusionMatrix # To use a confusion matrix to evaluate model\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device agnostic code\n",
        "device  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "47x6MY7sktW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Splitting data into training and testing sets"
      ],
      "metadata": {
        "id": "LO-8YgAPPN3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "# Set up testing data\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "# print length of each dataset\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "gOUO1avmk9dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of class names in FashionMNIST\n",
        "class_names = train_data.classes\n",
        "\n",
        "# Visualize samples of data to ensure proper installation\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols = 3, 3\n",
        "for i in range(1, rows*cols+1):\n",
        "  random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "  img, label = train_data[random_idx]\n",
        "  fig.add_subplot(rows, cols,i)\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "gMCzLVnZmLJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup batch size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Turn data into batches\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=False)\n",
        "\n",
        "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
        "print(f\"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
      ],
      "metadata": {
        "id": "DkSFuVDjmqO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining model"
      ],
      "metadata": {
        "id": "GustodvqPZF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a convolutional neural network (CNN)\n",
        "class FashionMNISTModel(nn.Module):\n",
        "  \"\"\"\n",
        "  Replicates Tiny VGG architecture\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    #print(f\"Input shape: {x.shape}\")\n",
        "    x = self.conv_block_1(x)\n",
        "    #print(f\"Block 1 output shape: {x.shape}\")\n",
        "    x = self.conv_block_2(x)\n",
        "    #print(f\"Block 1 output shape: {x.shape}\")\n",
        "    x = self.classifier(x)\n",
        "    #print(f\"Output shape: {x.shape}\")\n",
        "    return x\n",
        "\n",
        "# Initialize and instance of model\n",
        "main_model = FashionMNISTModel(input_shape=1, # input is a 28x28 image\n",
        "                               hidden_units=10, # 10 hidden units per layer\n",
        "                               output_shape=len(class_names)) # output for each of the labels in FashionMNIST\n"
      ],
      "metadata": {
        "id": "vudnfjdNnfxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining loss function, optimizer and evaluation functions"
      ],
      "metadata": {
        "id": "9sjXUgJ3Rt_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=main_model.parameters(),\n",
        "                            lr=0.1)"
      ],
      "metadata": {
        "id": "QPkzsTH0pMdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_train_time(start: float, end: float):\n",
        "  \"\"\"Calculates total train time of model\n",
        "\n",
        "  Args:\n",
        "    start (float): Start time of training/evaluation loop\n",
        "    end (float):  End time of training/evaluation loop\n",
        "\n",
        "  Returns:\n",
        "    [float]: Total time of training/evaluation loop\n",
        "  \"\"\"\n",
        "  total_time = end - start\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "hb8hkBi7p9Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(data_pred: torch.Tensor, data_true: torch.Tensor):\n",
        "  \"\"\"Calculates accuracy for model training and testing\n",
        "  Args:\n",
        "    data_pred (torch.Tensor): Predictions made by the model\n",
        "    data_true (torch.Tensor): The true data labels that are to be compared to the predictions of the model\n",
        "\n",
        "  Returns:\n",
        "    [torch.float]: Accuracy value of predictions compared to the true labels in percentage form\n",
        "  \"\"\"\n",
        "  acc = ( (torch.eq(data_true, data_pred).sum().item()) / len(data_pred)) * 100\n",
        "  return acc"
      ],
      "metadata": {
        "id": "YYUqqft5qfyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training model"
      ],
      "metadata": {
        "id": "A5PvQK2TPHwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing loop\n",
        "torch.manual_seed(100)\n",
        "torch.cuda.manual_seed(100)\n",
        "\n",
        "train_time_start = timer() # start timer\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "\n",
        "  print(f\"Epoch: {epoch+1} =================================\")\n",
        "\n",
        "### Testing\n",
        "  main_model.train()\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "\n",
        "    # Put data on target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Forward Pass\n",
        "    y_logits = main_model(X)\n",
        "\n",
        "    # Calculate and accumulate loss/acc\n",
        "    loss = loss_fn(y_logits, y)\n",
        "    train_loss += loss\n",
        "    train_acc += calc_accuracy(data_pred=y_logits.argmax(dim=1), # converts raw logits to prediction labels\n",
        "                               data_true=y)\n",
        "\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Stochastic gradient descent (SGD)\n",
        "    optimizer.step()\n",
        "\n",
        "  # Find average train loss and acc over entire dataset\n",
        "  train_loss /= len(train_dataloader)\n",
        "  train_acc /= len(train_dataloader)\n",
        "  print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")\n",
        "\n",
        "### Testing\n",
        "  main_model.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    for batch, (X, y) in enumerate(test_dataloader):\n",
        "\n",
        "      # Put data on target device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # Forward Pass\n",
        "      test_logits = main_model(X)\n",
        "\n",
        "      # Calculate and accumulate loss/acc\n",
        "      loss = loss_fn(test_logits, y)\n",
        "      test_loss += loss\n",
        "      test_acc += calc_accuracy(data_pred=test_logits.argmax(dim=1), # converts raw logits to prediction labels\n",
        "                               data_true=y)\n",
        "\n",
        "    #  Find average test loss and acc over entire dataset\n",
        "    test_loss /= len(test_dataloader)\n",
        "    test_acc /= len(test_dataloader)\n",
        "    print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\\n\")\n",
        "\n",
        "\n",
        "\n",
        "train_time_end = timer() # stop timer\n",
        "\n"
      ],
      "metadata": {
        "id": "OD3cWAk7oG37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_train_time = calc_train_time(start=train_time_start, end=train_time_end)\n",
        "if total_train_time >= 60:\n",
        "  total_train_time /= 60\n",
        "  print(f\"Training model took: {total_train_time:.2f} minutes\")\n",
        "else:\n",
        "  print(f\"Training model took: {total_train_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "uPf9yK70KarE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing model"
      ],
      "metadata": {
        "id": "3YFPVxfoPDuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make test samples\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_data), k=16):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "pred_probs = []\n",
        "main_model.to(device)\n",
        "main_model.eval()\n",
        "with torch.inference_mode():\n",
        "  for sample in test_samples:\n",
        "\n",
        "    sample = torch.unsqueeze(sample, dim=0).to(device)\n",
        "\n",
        "    pred_logit = main_model(sample)\n",
        "    pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
        "    pred_probs.append(pred_prob.cpu())\n",
        "\n",
        "pred_probs = torch.stack(pred_probs)\n",
        "\n",
        "# Convert prediction probabilites to labels\n",
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "pred_classes\n",
        "\n",
        "# Plot random predictions (re-run this cell for different images and predictions)\n",
        "plt.figure(figsize=(12,12))\n",
        "\n",
        "for i, sample in enumerate(test_samples):\n",
        "\n",
        "  # 4x4 matrix of images\n",
        "  plt.subplot(4, 4, i+1)\n",
        "\n",
        "  # Plot the target image\n",
        "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
        "\n",
        "  # Find the prediction label in text form\n",
        "  pred_label = class_names[pred_classes[i]]\n",
        "\n",
        "  # Get the truth label in test form\n",
        "  truth_label = class_names[test_labels[i]]\n",
        "\n",
        "  # Create a title for the plot\n",
        "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "  # green if correct and red if incorrect\n",
        "  if pred_label == truth_label:\n",
        "    plt.title(title_text, fontsize=10, c=\"g\")\n",
        "  else:\n",
        "    plt.title(title_text, fontsize=10, c=\"r\")\n",
        "\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "MFJq23g0Phpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using a confusion matrix"
      ],
      "metadata": {
        "id": "Xk9jelnTRmrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_preds = []\n",
        "main_model.eval()\n",
        "with torch.inference_mode():\n",
        "  for (X, y) in tqdm(test_dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_logits = main_model(X)\n",
        "    y_pred = torch.softmax(y_logits.squeeze(), dim=0).argmax(dim=1) # logits -> labels\n",
        "    y_preds.append(y_pred.cpu()) # put label on cpu before appending\n",
        "y_pred_tensor = torch.cat(y_preds)# Concatenate list of preds into a tensor"
      ],
      "metadata": {
        "id": "bT_CRnjQRYU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confmat = ConfusionMatrix(num_classes=len(class_names), task=\"multiclass\")\n",
        "confmat_tensor = confmat(preds=y_pred_tensor, target=test_data.targets)\n",
        "\n",
        "# Plot  confusion matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=confmat_tensor.numpy(), # matplotlib uses numpy arrays\n",
        "                                class_names=class_names,\n",
        "                                figsize=(10,7),\n",
        "                                colorbar=True)"
      ],
      "metadata": {
        "id": "6xs2pL0fR-zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving model"
      ],
      "metadata": {
        "id": "FxBMkZtLSIws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory path\n",
        "DOWNLOAD_PATH = Path(\"models\")\n",
        "DOWNLOAD_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Create model save\n",
        "MODEL_NAME = \"main_model.pth\"\n",
        "MODEL_DOWNLOAD_PATH = DOWNLOAD_PATH / MODEL_NAME\n",
        "\n",
        "# Save model state dict\n",
        "print(f\"Saving model to: {MODEL_DOWNLOAD_PATH}\")\n",
        "torch.save(obj=main_model.state_dict(), f=MODEL_DOWNLOAD_PATH)"
      ],
      "metadata": {
        "id": "GnNa6C9eSKRf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}